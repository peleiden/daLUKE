#!/usr/bin/env python3
from __future__ import annotations
import os

import torch
from pelutils import log, Levels, Parser

import daluke.data as datasets

from daluke import cuda
from daluke.collect_modelfile import OUT_FILE as collect_out
from daluke.model import load_from_archive, save_to_archive, DaLukeNER, mutate_for_ner
from daluke.train import TrainNER
from daluke.data import NERDataset, Split

OUT_FILE = "daluke_ner.tar.gz"

ARGUMENTS = {
    "model": {
        "help": "directory or .tar.gz file containing the model, metadata and entity vocab generated by collect_modelfile",
        "default": os.path.join("local_data", collect_out)
    },
    "lr":              {"default": 5e-5, "type": float},
    "epochs":          {"default": 5, "type": int},
    "batch-size":      {"default": 2, "type": int},
    "adam-b1":         {"default": 0.9, "type": float},
    "adam-b2":         {"default": 0.98, "type": float},
    "warmup-prop":     {"default": 0.06, "type": float},
    "grad-accumulate": {"default": 2, "type": int},
    "weight-decay":    {"default": 0.01, "type": float},

    "quieter": {"help": "Don't show debug logging", "action": "store_true"},
    "cpu":     {"help": "Run experiment on cpu",    "action": "store_true"},
    "dataset": {"help": "Which dataset to use. Currently, only DaNE supported", "default": "DaNE"},
}

def run_experiment(args: dict[str, str]):
    device = torch.device("cpu") if args["cpu"] else cuda
    entity_vocab, metadata, state_dict = load_from_archive(args["model"])
    state_dict = mutate_for_ner(state_dict, entity_vocab)

    log.debug("Loading dataset ...")
    dataset = getattr(datasets, args["dataset"])
    dataset: NERDataset = dataset()
    dataloader = dataset.build(Split.TRAIN, args["batch_size"])

    log.debug("Loading model ...")
    model = DaLukeNER(metadata["model_config"], output_shape=len(dataset.all_labels))
    model.load_state_dict(state_dict, strict=False)
    model.to(device)

    log(f"Starting training of DaLUKE for NER on {args['dataset']}")
    training = TrainNER(model, dataloader, args["epochs"],
        grad_accumulate = args["grad_accumulate"],
        lr              = args["lr"],
        adam_betas      = (args["adam_b1"], args["adam_b2"]),
        warmup_prop     = args["warmup_prop"],
        weight_decay    = args["weight_decay"],
        device          = device,
    )

    training.run()

    os.makedirs(args["location"], exist_ok=True)
    outpath = os.path.join(args["location"], OUT_FILE)
    save_to_archive(outpath, entity_vocab, metadata, model)
    log("Training complete, saved model archive to", outpath)

if __name__ == '__main__':
    with log.log_errors:
        parser = Parser(ARGUMENTS, name="daLUKE-NER-finetune", multiple_jobs=True)
        experiments = parser.parse()
        parser.document_settings()
        log.configure(
            os.path.join(parser.location, "daluke_train_ner.log"), "Finetune daLUKE for Danish NER",
            print_level=Levels.INFO if experiments[0]["quieter"] else Levels.DEBUG
        )
        for exp in experiments:
            run_experiment(exp)
